{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import models, layers\n",
    "import splitfolders\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1335 images belonging to 7 classes.\n",
      "Found 170 images belonging to 7 classes.\n",
      "Found 168 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "input_folder = r'/informatik1/students/home/1rieper/Documents/infhome/ASL_Alphabet_Dataset_slim/asl_alphabet_train'\n",
    "output_folder = r'/informatik1/students/home/1rieper/Documents/infhome/ASL_Alphabet_Dataset_slim/sorted'\n",
    "\n",
    "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(0.8, 0.1, 0.1))\n",
    "\n",
    "\n",
    "target_size = (200, 200)\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    output_folder + '/train',\n",
    "    target_size=target_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    output_folder + '/val',\n",
    "    target_size=target_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    output_folder + '/test',\n",
    "    target_size=target_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 10:16:30.027662: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 10:16:30.042371: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 10:16:30.042507: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 10:16:30.044073: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 10:16:30.044228: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 10:16:30.044322: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 10:16:30.124995: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 10:16:30.125121: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 10:16:30.125223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 10:16:30.125299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4744 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 10:16:32.271485: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-01-12 10:16:39.195186: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f0a30d1dd80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-12 10:16:39.195220: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5\n",
      "2024-01-12 10:16:39.199708: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705050999.271593   41886 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-01-12 10:16:50.304120: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-12 10:16:50.304153: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-12 10:16:50.667101: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-12 10:16:50.667121: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 57s 844ms/step - loss: 2.1998 - accuracy: 0.1363 - val_loss: 1.9456 - val_accuracy: 0.1471\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 18s 415ms/step - loss: 1.9457 - accuracy: 0.1468 - val_loss: 1.9452 - val_accuracy: 0.1471\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 18s 415ms/step - loss: 1.9454 - accuracy: 0.1491 - val_loss: 1.9450 - val_accuracy: 0.1471\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9451 - accuracy: 0.1678 - val_loss: 1.9448 - val_accuracy: 0.1471\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 18s 415ms/step - loss: 1.9454 - accuracy: 0.1483 - val_loss: 1.9446 - val_accuracy: 0.1471\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 21s 501ms/step - loss: 1.9450 - accuracy: 0.1536 - val_loss: 1.9446 - val_accuracy: 0.1471\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 32s 748ms/step - loss: 1.9447 - accuracy: 0.1513 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 18s 415ms/step - loss: 1.9445 - accuracy: 0.1506 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 18s 414ms/step - loss: 1.9444 - accuracy: 0.1566 - val_loss: 1.9443 - val_accuracy: 0.1471\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 18s 415ms/step - loss: 1.9446 - accuracy: 0.1551 - val_loss: 1.9443 - val_accuracy: 0.1471\n",
      "6/6 [==============================] - 3s 621ms/step - loss: 1.9443 - accuracy: 0.1548\n",
      "Test loss: 1.944337248802185\n",
      "Test accuracy: 0.1547619104385376\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(target_size[0], target_size[1], 3))\n",
    "\n",
    "# Schritt 4: Fügen Sie dem VGG16-Modell einen benutzerdefinierten Klassifikator hinzu\n",
    "model = models.Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(7, activation='softmax'))  # Ändern Sie dies entsprechend der Anzahl Ihrer Klassen\n",
    "\n",
    "# Schritt 5: Kompilieren Sie das Modell\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Schritt 6: Trainieren Sie das Modell\n",
    "model.fit(train_generator, epochs=10, validation_data=val_generator)\n",
    "\n",
    "# Schritt 7: Bewerten Sie das Modell auf dem Testset\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1335 images belonging to 7 classes.\n",
      "Epoch 1/20\n",
      "42/42 [==============================] - 21s 425ms/step - loss: 2.6159 - accuracy: 0.1581 - val_loss: 1.9459 - val_accuracy: 0.1471\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 18s 416ms/step - loss: 1.9875 - accuracy: 0.1348 - val_loss: 1.9452 - val_accuracy: 0.1412\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 18s 418ms/step - loss: 1.9481 - accuracy: 0.1461 - val_loss: 1.9442 - val_accuracy: 0.1647\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 18s 416ms/step - loss: 1.9458 - accuracy: 0.1401 - val_loss: 1.9441 - val_accuracy: 0.1647\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9451 - accuracy: 0.1558 - val_loss: 1.9442 - val_accuracy: 0.1471\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9443 - val_accuracy: 0.1471\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9455 - accuracy: 0.1468 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9450 - accuracy: 0.1528 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 18s 419ms/step - loss: 1.9452 - accuracy: 0.1513 - val_loss: 1.9442 - val_accuracy: 0.1471\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9452 - accuracy: 0.1588 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 18s 427ms/step - loss: 1.9458 - accuracy: 0.1573 - val_loss: 1.9440 - val_accuracy: 0.1471\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9456 - accuracy: 0.1610 - val_loss: 1.9439 - val_accuracy: 0.1471\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9455 - accuracy: 0.1468 - val_loss: 1.9441 - val_accuracy: 0.1471\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 18s 416ms/step - loss: 1.9452 - accuracy: 0.1521 - val_loss: 1.9442 - val_accuracy: 0.1471\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9444 - accuracy: 0.1498 - val_loss: 1.9441 - val_accuracy: 0.1471\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 18s 418ms/step - loss: 1.9458 - accuracy: 0.1558 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 18s 418ms/step - loss: 1.9444 - accuracy: 0.1491 - val_loss: 1.9443 - val_accuracy: 0.1471\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9449 - accuracy: 0.1461 - val_loss: 1.9445 - val_accuracy: 0.1471\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 1.9446 - accuracy: 0.1491 - val_loss: 1.9441 - val_accuracy: 0.1471\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 18s 423ms/step - loss: 1.9468 - accuracy: 0.1446 - val_loss: 1.9446 - val_accuracy: 0.1471\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 1.9443 - accuracy: 0.1548\n",
      "Test loss: 1.9442745447158813\n",
      "Test accuracy: 0.1547619104385376\n"
     ]
    }
   ],
   "source": [
    "# Schritt 3: Laden Sie das vorab trainierte VGG16-Modell\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(target_size[0], target_size[1], 3))\n",
    "\n",
    "# Schritt 4: Fügen Sie dem VGG16-Modell einen benutzerdefinierten Klassifikator hinzu\n",
    "model = models.Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Schritt 5: Kompilieren Sie das Modell\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Schritt 6: Trainieren Sie das Modell mit längerer Trainingsdauer und Daten Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(output_folder + '/train', target_size=target_size, batch_size=32, class_mode='categorical')\n",
    "\n",
    "model.fit(train_generator, epochs=20, validation_data=val_generator)\n",
    "\n",
    "# Schritt 7: Bewerten Sie das Modell auf dem Testset\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1335 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 10:45:59.028066: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-12 10:45:59.278955: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-12 10:46:00.120426: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-12 10:46:00.120462: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-12 10:46:00.256445: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-12 10:46:00.256468: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 93s 2s/step - loss: 2.1943 - accuracy: 0.2255 - val_loss: 1.7073 - val_accuracy: 0.3235\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 15s 346ms/step - loss: 1.6767 - accuracy: 0.2944 - val_loss: 1.5901 - val_accuracy: 0.3882\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 15s 346ms/step - loss: 1.6325 - accuracy: 0.3086 - val_loss: 1.4866 - val_accuracy: 0.4059\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 14s 343ms/step - loss: 1.5595 - accuracy: 0.3483 - val_loss: 1.4296 - val_accuracy: 0.4588\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 15s 360ms/step - loss: 1.5123 - accuracy: 0.3843 - val_loss: 1.3788 - val_accuracy: 0.4765\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 16s 382ms/step - loss: 1.4624 - accuracy: 0.4120 - val_loss: 1.4027 - val_accuracy: 0.4529\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 19s 454ms/step - loss: 1.3653 - accuracy: 0.4674 - val_loss: 1.4061 - val_accuracy: 0.4529\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 15s 362ms/step - loss: 1.3639 - accuracy: 0.4554 - val_loss: 1.2043 - val_accuracy: 0.5059\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 15s 354ms/step - loss: 1.2943 - accuracy: 0.5026 - val_loss: 1.0786 - val_accuracy: 0.6118\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 15s 349ms/step - loss: 1.2441 - accuracy: 0.5056 - val_loss: 1.0370 - val_accuracy: 0.5529\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 15s 347ms/step - loss: 1.1716 - accuracy: 0.5573 - val_loss: 1.0274 - val_accuracy: 0.5588\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 15s 346ms/step - loss: 1.1267 - accuracy: 0.5663 - val_loss: 1.0721 - val_accuracy: 0.5588\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 15s 344ms/step - loss: 1.0829 - accuracy: 0.5790 - val_loss: 1.0313 - val_accuracy: 0.6176\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 14s 339ms/step - loss: 1.1322 - accuracy: 0.5835 - val_loss: 0.8920 - val_accuracy: 0.6294\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 14s 342ms/step - loss: 1.0355 - accuracy: 0.6187 - val_loss: 0.9098 - val_accuracy: 0.6765\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 14s 341ms/step - loss: 1.0011 - accuracy: 0.6277 - val_loss: 0.8466 - val_accuracy: 0.7235\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 15s 346ms/step - loss: 0.9790 - accuracy: 0.6135 - val_loss: 0.9822 - val_accuracy: 0.6235\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 15s 353ms/step - loss: 0.9502 - accuracy: 0.6375 - val_loss: 0.8065 - val_accuracy: 0.6941\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 15s 347ms/step - loss: 0.9062 - accuracy: 0.6629 - val_loss: 0.7653 - val_accuracy: 0.7059\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 15s 344ms/step - loss: 0.9506 - accuracy: 0.6352 - val_loss: 0.7473 - val_accuracy: 0.7471\n",
      "6/6 [==============================] - 8s 2s/step - loss: 0.4995 - accuracy: 0.8452\n",
      "Test loss: 0.4995386004447937\n",
      "Test accuracy: 0.8452380895614624\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(target_size[0], target_size[1], 3))\n",
    "\n",
    "# Schritt 4: Fügen Sie dem VGG16-Modell einen benutzerdefinierten Klassifikator hinzu\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(target_size[0], target_size[1], 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Schritt 6: Trainieren Sie das Modell mit längerer Trainingsdauer und Daten Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(output_folder + '/train', target_size=target_size, batch_size=32, class_mode='categorical')\n",
    "\n",
    "model.fit(train_generator, epochs=20, validation_data=val_generator)\n",
    "\n",
    "# Schritt 7: Bewerten Sie das Modell auf dem Testset\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1335 images belonging to 7 classes.\n",
      "Epoch 1/20\n",
      "42/42 [==============================] - 53s 1s/step - loss: 2.2546 - accuracy: 0.1386 - val_loss: 1.9453 - val_accuracy: 0.1471\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 15s 341ms/step - loss: 1.9458 - accuracy: 0.1408 - val_loss: 1.9452 - val_accuracy: 0.1412\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 15s 344ms/step - loss: 1.9458 - accuracy: 0.1468 - val_loss: 1.9449 - val_accuracy: 0.1471\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 15s 348ms/step - loss: 1.9453 - accuracy: 0.1476 - val_loss: 1.9446 - val_accuracy: 0.1471\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 15s 351ms/step - loss: 1.9452 - accuracy: 0.1536 - val_loss: 1.9447 - val_accuracy: 0.1471\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 15s 342ms/step - loss: 1.9447 - accuracy: 0.1528 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 15s 348ms/step - loss: 1.9452 - accuracy: 0.1543 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 15s 345ms/step - loss: 1.9445 - accuracy: 0.1536 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 15s 349ms/step - loss: 1.9454 - accuracy: 0.1521 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 15s 362ms/step - loss: 1.9450 - accuracy: 0.1528 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 15s 362ms/step - loss: 1.9451 - accuracy: 0.1528 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 15s 343ms/step - loss: 1.9447 - accuracy: 0.1528 - val_loss: 1.9445 - val_accuracy: 0.1471\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 15s 346ms/step - loss: 1.9450 - accuracy: 0.1528 - val_loss: 1.9445 - val_accuracy: 0.1471\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 15s 344ms/step - loss: 1.9448 - accuracy: 0.1528 - val_loss: 1.9444 - val_accuracy: 0.1471\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 15s 347ms/step - loss: 1.9448 - accuracy: 0.1528 - val_loss: 1.9443 - val_accuracy: 0.1471\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 15s 345ms/step - loss: 2.0862 - accuracy: 0.1521 - val_loss: 1.9457 - val_accuracy: 0.1471\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 15s 346ms/step - loss: 1.9453 - accuracy: 0.1528 - val_loss: 1.9454 - val_accuracy: 0.1471\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 15s 343ms/step - loss: 1.9449 - accuracy: 0.1528 - val_loss: 1.9449 - val_accuracy: 0.1471\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 15s 345ms/step - loss: 1.9454 - accuracy: 0.1528 - val_loss: 1.9446 - val_accuracy: 0.1471\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 15s 345ms/step - loss: 1.9448 - accuracy: 0.1528 - val_loss: 1.9445 - val_accuracy: 0.1471\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9443 - accuracy: 0.1548\n",
      "Test loss: 1.9442663192749023\n",
      "Test accuracy: 0.1547619104385376\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(target_size[0], target_size[1], 3))\n",
    "\n",
    "for layer in vgg_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Schritt 6: Trainieren Sie das Modell mit längerer Trainingsdauer und Daten Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(output_folder + '/train', target_size=target_size, batch_size=32, class_mode='categorical')\n",
    "\n",
    "model.fit(train_generator, epochs=20, validation_data=val_generator)\n",
    "\n",
    "# Schritt 7: Bewerten Sie das Modell auf dem Testset\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
