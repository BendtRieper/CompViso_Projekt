{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Durchsuche alle Unterordner nach .jpg und .jpeg Dateien und füge sie zur Liste hinzu\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(folder_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/*.jp*g\u001b[39m\u001b[38;5;124m'\u001b[39m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m----> 9\u001b[0m     trainImg\u001b[38;5;241m.\u001b[39mappend(resize(\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m, (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m)))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Konvertieren Sie Bilder in eine 2D-Array-Darstellung\u001b[39;00m\n\u001b[0;32m     12\u001b[0m image_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([img\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m trainImg])\n",
      "File \u001b[1;32mc:\\Users\\tim-b\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\skimage\\io\\_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname:\n\u001b[1;32m---> 53\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcall_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\tim-b\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\skimage\\io\\manage_plugins.py:205\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tim-b\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimageio_imread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     13\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\tim-b\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imageio\\v3.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(img_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs))\n",
      "File \u001b[1;32mc:\\Users\\tim-b\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imageio\\core\\imopen.py:196\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     plugin_instance \u001b[38;5;241m=\u001b[39m \u001b[43mcandidate_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InitializationError:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;66;03m# file extension doesn't match file type\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tim-b\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imageio\\plugins\\pillow.py:104\u001b[0m, in \u001b[0;36mPillowPlugin.__init__\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mio_mode \u001b[38;5;241m==\u001b[39m IOMode\u001b[38;5;241m.\u001b[39mread:\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    105\u001b[0m             \u001b[38;5;66;03m# Check if it is generally possible to read the image.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;66;03m# This will not read any data and merely try to find a\u001b[39;00m\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;66;03m# compatible pillow plugin (ref: the pillow docs).\u001b[39;00m\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnidentifiedImageError:\n",
      "File \u001b[1;32mc:\\Users\\tim-b\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imageio\\core\\request.py:492\u001b[0m, in \u001b[0;36mRequest.get_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 492\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uri_type \u001b[38;5;241m==\u001b[39m URI_ZIPPED:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# Get the correct filename\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     filename, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename_zip\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Liste für Trainingsbilder\n",
    "trainImg = []\n",
    "\n",
    "# Pfad zum Ordner mit den Bildern\n",
    "folder_path = './PraktikumCV/ASL_Alphabet_Dataset/asl_alphabet_train/A/'\n",
    "\n",
    "# Durchsuche alle Unterordner nach .jpg und .jpeg Dateien und füge sie zur Liste hinzu\n",
    "for img_path in glob.glob(folder_path + '/*.jp*g', recursive=True):\n",
    "    trainImg.append(resize(imread(img_path), (200, 200)))\n",
    "\n",
    "# Konvertieren Sie Bilder in eine 2D-Array-Darstellung\n",
    "image_array = np.array([img.flatten() for img in trainImg])\n",
    "\n",
    "# Drucke die Anzahl der gefundenen Bilder\n",
    "print(f\"Anzahl der gefundenen Bilder: {len(trainImg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(img_array), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Feature-Extraktion mit VGG16\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m vgg16_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainImg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(img_array)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(img_array):\n\u001b[1;32m----> 6\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     features \u001b[38;5;241m=\u001b[39m vgg16_model\u001b[38;5;241m.\u001b[39mpredict(img_array)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(img_array), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\tim-b\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\applications\\vgg16.py:257\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.applications.vgg16.preprocess_input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_input\u001b[39m(x, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimagenet_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcaffe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tim-b\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\applications\\imagenet_utils.py:122\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected data_format to be one of `channels_first` or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`channels_last`. Received: data_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_preprocess_numpy_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _preprocess_symbolic_input(x, data_format\u001b[38;5;241m=\u001b[39mdata_format, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[1;32mc:\\Users\\tim-b\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\applications\\imagenet_utils.py:241\u001b[0m, in \u001b[0;36m_preprocess_numpy_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    239\u001b[0m             x[:, \u001b[38;5;241m2\u001b[39m, :, :] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m std[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m     \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m mean[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    242\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m mean[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    243\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m mean[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Laden Sie das VGG16-Modell vor, ohne die oberste Schicht (ohne Klassifizierungsschicht)\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "# Funktion zur Feature-Extraktion mit VGG16\n",
    "def extract_features(img_array):\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = vgg16_model.predict(img_array)\n",
    "    return features.reshape((len(img_array), -1))\n",
    "\n",
    "# Feature-Extraktion mit VGG16\n",
    "vgg16_features = extract_features(np.array(trainImg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imsave\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Annahme: vgg16_features und trainImg sind bereits definiert\n",
    "\n",
    "# Features normalisieren\n",
    "normalized_features = StandardScaler().fit_transform(vgg16_features)\n",
    "\n",
    "# Hier KDTree\n",
    "kdtree = KDTree(normalized_features, metric='euclidean')\n",
    "\n",
    "# Festlege der Entfernungsschwelle für Clustering\n",
    "distance_threshold = 2\n",
    "\n",
    "# Finde Nachbarn für jeden Punkt\n",
    "neighbors = kdtree.query_radius(normalized_features, distance_threshold)\n",
    "\n",
    "# Erstelle Cluster-Labels\n",
    "labels = np.zeros(len(normalized_features), dtype=int)\n",
    "current_label = 1\n",
    "\n",
    "for i, neighbor_list in enumerate(neighbors):\n",
    "    if labels[i] == 0:  # Punkt noch nicht in einem Cluster\n",
    "        labels[neighbor_list] = current_label\n",
    "        current_label += 1\n",
    "\n",
    "# Berechne die Centroids der Cluster\n",
    "cluster_centroids = []\n",
    "for cluster_label in np.unique(labels):\n",
    "        cluster_points = normalized_features[labels == cluster_label]\n",
    "        cluster_centroid = np.mean(cluster_points, axis=0)\n",
    "        cluster_centroids.append(cluster_centroid)\n",
    "\n",
    "cluster_centroids = np.array(cluster_centroids)\n",
    "\n",
    "# Extrahiere eindeutige Bilder basierend auf den Clustern\n",
    "unique_images = [trainImg[i] for i in np.unique(labels) if i != -1]\n",
    "\n",
    "# Finde die Indizes der Centroids in den ursprünglichen Bildern\n",
    "centroid_indices = []\n",
    "for centroid in cluster_centroids:\n",
    "    nearest_neighbor_distance, nearest_neighbor_index = kdtree.query(centroid.reshape(1, -1), k=1)\n",
    "    centroid_indices.append(nearest_neighbor_index[0][0])\n",
    "\n",
    "# Extrahiere die Bilder der Centroids\n",
    "centroid_images = [trainImg[i] for i in centroid_indices]\n",
    "\n",
    "# Speicherpfad für eindeutige Bilder\n",
    "output_folder = './PraktikumCV/ASL_unique/A/'\n",
    "os.makedirs(output_folder, exist_ok=True)  # Erstelle den Ordner, falls er nicht existiert\n",
    "\n",
    "# Batch-Verarbeitung und direktes Speichern\n",
    "for img_index, output_path in zip(centroid_indices, [os.path.join(output_folder, f'unique_image_{i}.jpg') for i in range(len(centroid_indices))]):\n",
    "    img = trainImg[img_index]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    imsave(output_path, img)\n",
    "    plt.close()\n",
    "\n",
    "print(\"Eindeutige Bilder (Centroids) wurden im Zielordner gespeichert:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste für Trainingsbilder\n",
    "trainImg = []\n",
    "\n",
    "# Pfad zum Ordner mit den Bildern\n",
    "folder_path = './PraktikumCV/ASL_Alphabet_Dataset/asl_alphabet_train/B/'\n",
    "\n",
    "# Durchsuche alle Unterordner nach .jpg und .jpeg Dateien und füge sie zur Liste hinzu\n",
    "for img_path in glob.glob(folder_path + '/*.jp*g', recursive=True):\n",
    "    trainImg.append(resize(imread(img_path), (200, 200)))\n",
    "\n",
    "# Konvertieren Sie Bilder in eine 2D-Array-Darstellung\n",
    "image_array = np.array([img.flatten() for img in trainImg])\n",
    "\n",
    "# Drucke die Anzahl der gefundenen Bilder\n",
    "print(f\"Anzahl der gefundenen Bilder: {len(trainImg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden Sie das VGG16-Modell vor, ohne die oberste Schicht (ohne Klassifizierungsschicht)\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "# Funktion zur Feature-Extraktion mit VGG16\n",
    "def extract_features(img_array):\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = vgg16_model.predict(img_array)\n",
    "    return features.reshape((len(img_array), -1))\n",
    "\n",
    "# Feature-Extraktion mit VGG16\n",
    "vgg16_features = extract_features(np.array(trainImg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imsave\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Annahme: vgg16_features und trainImg sind bereits definiert\n",
    "\n",
    "# Features normalisieren\n",
    "normalized_features = StandardScaler().fit_transform(vgg16_features)\n",
    "\n",
    "# Hier KDTree\n",
    "kdtree = KDTree(normalized_features, metric='euclidean')\n",
    "\n",
    "# Festlege der Entfernungsschwelle für Clustering\n",
    "distance_threshold = 2\n",
    "\n",
    "# Finde Nachbarn für jeden Punkt\n",
    "neighbors = kdtree.query_radius(normalized_features, distance_threshold)\n",
    "\n",
    "# Erstelle Cluster-Labels\n",
    "labels = np.zeros(len(normalized_features), dtype=int)\n",
    "current_label = 1\n",
    "\n",
    "for i, neighbor_list in enumerate(neighbors):\n",
    "    if labels[i] == 0:  # Punkt noch nicht in einem Cluster\n",
    "        labels[neighbor_list] = current_label\n",
    "        current_label += 1\n",
    "\n",
    "# Berechne die Centroids der Cluster\n",
    "cluster_centroids = []\n",
    "for cluster_label in np.unique(labels):\n",
    "        cluster_points = normalized_features[labels == cluster_label]\n",
    "        cluster_centroid = np.mean(cluster_points, axis=0)\n",
    "        cluster_centroids.append(cluster_centroid)\n",
    "\n",
    "cluster_centroids = np.array(cluster_centroids)\n",
    "\n",
    "# Extrahiere eindeutige Bilder basierend auf den Clustern\n",
    "unique_images = [trainImg[i] for i in np.unique(labels) if i != -1]\n",
    "\n",
    "# Finde die Indizes der Centroids in den ursprünglichen Bildern\n",
    "centroid_indices = []\n",
    "for centroid in cluster_centroids:\n",
    "    nearest_neighbor_distance, nearest_neighbor_index = kdtree.query(centroid.reshape(1, -1), k=1)\n",
    "    centroid_indices.append(nearest_neighbor_index[0][0])\n",
    "\n",
    "# Extrahiere die Bilder der Centroids\n",
    "centroid_images = [trainImg[i] for i in centroid_indices]\n",
    "\n",
    "# Speicherpfad für eindeutige Bilder\n",
    "output_folder = './PraktikumCV/ASL_unique/B/'\n",
    "os.makedirs(output_folder, exist_ok=True)  # Erstelle den Ordner, falls er nicht existiert\n",
    "\n",
    "# Batch-Verarbeitung und direktes Speichern\n",
    "for img_index, output_path in zip(centroid_indices, [os.path.join(output_folder, f'unique_image_{i}.jpg') for i in range(len(centroid_indices))]):\n",
    "    img = trainImg[img_index]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    imsave(output_path, img)\n",
    "    plt.close()\n",
    "\n",
    "print(\"Eindeutige Bilder (Centroids) wurden im Zielordner gespeichert:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste für Trainingsbilder\n",
    "trainImg = []\n",
    "\n",
    "# Pfad zum Ordner mit den Bildern\n",
    "folder_path = './PraktikumCV/ASL_Alphabet_Dataset/asl_alphabet_train/C/'\n",
    "\n",
    "# Durchsuche alle Unterordner nach .jpg und .jpeg Dateien und füge sie zur Liste hinzu\n",
    "for img_path in glob.glob(folder_path + '/*.jp*g', recursive=True):\n",
    "    trainImg.append(resize(imread(img_path), (200, 200)))\n",
    "\n",
    "# Konvertieren Sie Bilder in eine 2D-Array-Darstellung\n",
    "image_array = np.array([img.flatten() for img in trainImg])\n",
    "\n",
    "# Drucke die Anzahl der gefundenen Bilder\n",
    "print(f\"Anzahl der gefundenen Bilder: {len(trainImg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden Sie das VGG16-Modell vor, ohne die oberste Schicht (ohne Klassifizierungsschicht)\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "# Funktion zur Feature-Extraktion mit VGG16\n",
    "def extract_features(img_array):\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = vgg16_model.predict(img_array)\n",
    "    return features.reshape((len(img_array), -1))\n",
    "\n",
    "# Feature-Extraktion mit VGG16\n",
    "vgg16_features = extract_features(np.array(trainImg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imsave\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Annahme: vgg16_features und trainImg sind bereits definiert\n",
    "\n",
    "# Features normalisieren\n",
    "normalized_features = StandardScaler().fit_transform(vgg16_features)\n",
    "\n",
    "# Hier KDTree\n",
    "kdtree = KDTree(normalized_features, metric='euclidean')\n",
    "\n",
    "# Festlege der Entfernungsschwelle für Clustering\n",
    "distance_threshold = 2\n",
    "\n",
    "# Finde Nachbarn für jeden Punkt\n",
    "neighbors = kdtree.query_radius(normalized_features, distance_threshold)\n",
    "\n",
    "# Erstelle Cluster-Labels\n",
    "labels = np.zeros(len(normalized_features), dtype=int)\n",
    "current_label = 1\n",
    "\n",
    "for i, neighbor_list in enumerate(neighbors):\n",
    "    if labels[i] == 0:  # Punkt noch nicht in einem Cluster\n",
    "        labels[neighbor_list] = current_label\n",
    "        current_label += 1\n",
    "\n",
    "# Berechne die Centroids der Cluster\n",
    "cluster_centroids = []\n",
    "for cluster_label in np.unique(labels):\n",
    "        cluster_points = normalized_features[labels == cluster_label]\n",
    "        cluster_centroid = np.mean(cluster_points, axis=0)\n",
    "        cluster_centroids.append(cluster_centroid)\n",
    "\n",
    "cluster_centroids = np.array(cluster_centroids)\n",
    "\n",
    "# Extrahiere eindeutige Bilder basierend auf den Clustern\n",
    "unique_images = [trainImg[i] for i in np.unique(labels) if i != -1]\n",
    "\n",
    "# Finde die Indizes der Centroids in den ursprünglichen Bildern\n",
    "centroid_indices = []\n",
    "for centroid in cluster_centroids:\n",
    "    nearest_neighbor_distance, nearest_neighbor_index = kdtree.query(centroid.reshape(1, -1), k=1)\n",
    "    centroid_indices.append(nearest_neighbor_index[0][0])\n",
    "\n",
    "# Extrahiere die Bilder der Centroids\n",
    "centroid_images = [trainImg[i] for i in centroid_indices]\n",
    "\n",
    "# Speicherpfad für eindeutige Bilder\n",
    "output_folder = './PraktikumCV/ASL_unique/C/'\n",
    "os.makedirs(output_folder, exist_ok=True)  # Erstelle den Ordner, falls er nicht existiert\n",
    "\n",
    "# Batch-Verarbeitung und direktes Speichern\n",
    "for img_index, output_path in zip(centroid_indices, [os.path.join(output_folder, f'unique_image_{i}.jpg') for i in range(len(centroid_indices))]):\n",
    "    img = trainImg[img_index]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    imsave(output_path, img)\n",
    "    plt.close()\n",
    "\n",
    "print(\"Eindeutige Bilder (Centroids) wurden im Zielordner gespeichert:\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste für Trainingsbilder\n",
    "trainImg = []\n",
    "\n",
    "# Pfad zum Ordner mit den Bildern\n",
    "folder_path = './PraktikumCV/ASL_Alphabet_Dataset/asl_alphabet_train/D/'\n",
    "\n",
    "# Durchsuche alle Unterordner nach .jpg und .jpeg Dateien und füge sie zur Liste hinzu\n",
    "for img_path in glob.glob(folder_path + '/*.jp*g', recursive=True):\n",
    "    trainImg.append(resize(imread(img_path), (200, 200)))\n",
    "\n",
    "# Konvertieren Sie Bilder in eine 2D-Array-Darstellung\n",
    "image_array = np.array([img.flatten() for img in trainImg])\n",
    "\n",
    "# Drucke die Anzahl der gefundenen Bilder\n",
    "print(f\"Anzahl der gefundenen Bilder: {len(trainImg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden Sie das VGG16-Modell vor, ohne die oberste Schicht (ohne Klassifizierungsschicht)\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "# Funktion zur Feature-Extraktion mit VGG16\n",
    "def extract_features(img_array):\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = vgg16_model.predict(img_array)\n",
    "    return features.reshape((len(img_array), -1))\n",
    "\n",
    "# Feature-Extraktion mit VGG16\n",
    "vgg16_features = extract_features(np.array(trainImg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imsave\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Annahme: vgg16_features und trainImg sind bereits definiert\n",
    "\n",
    "# Features normalisieren\n",
    "normalized_features = StandardScaler().fit_transform(vgg16_features)\n",
    "\n",
    "# Hier KDTree\n",
    "kdtree = KDTree(normalized_features, metric='euclidean')\n",
    "\n",
    "# Festlege der Entfernungsschwelle für Clustering\n",
    "distance_threshold = 2\n",
    "\n",
    "# Finde Nachbarn für jeden Punkt\n",
    "neighbors = kdtree.query_radius(normalized_features, distance_threshold)\n",
    "\n",
    "# Erstelle Cluster-Labels\n",
    "labels = np.zeros(len(normalized_features), dtype=int)\n",
    "current_label = 1\n",
    "\n",
    "for i, neighbor_list in enumerate(neighbors):\n",
    "    if labels[i] == 0:  # Punkt noch nicht in einem Cluster\n",
    "        labels[neighbor_list] = current_label\n",
    "        current_label += 1\n",
    "\n",
    "# Berechne die Centroids der Cluster\n",
    "cluster_centroids = []\n",
    "for cluster_label in np.unique(labels):\n",
    "        cluster_points = normalized_features[labels == cluster_label]\n",
    "        cluster_centroid = np.mean(cluster_points, axis=0)\n",
    "        cluster_centroids.append(cluster_centroid)\n",
    "\n",
    "cluster_centroids = np.array(cluster_centroids)\n",
    "\n",
    "# Extrahiere eindeutige Bilder basierend auf den Clustern\n",
    "unique_images = [trainImg[i] for i in np.unique(labels) if i != -1]\n",
    "\n",
    "# Finde die Indizes der Centroids in den ursprünglichen Bildern\n",
    "centroid_indices = []\n",
    "for centroid in cluster_centroids:\n",
    "    nearest_neighbor_distance, nearest_neighbor_index = kdtree.query(centroid.reshape(1, -1), k=1)\n",
    "    centroid_indices.append(nearest_neighbor_index[0][0])\n",
    "\n",
    "# Extrahiere die Bilder der Centroids\n",
    "centroid_images = [trainImg[i] for i in centroid_indices]\n",
    "\n",
    "# Speicherpfad für eindeutige Bilder\n",
    "output_folder = './PraktikumCV/ASL_unique/D/'\n",
    "os.makedirs(output_folder, exist_ok=True)  # Erstelle den Ordner, falls er nicht existiert\n",
    "\n",
    "# Batch-Verarbeitung und direktes Speichern\n",
    "for img_index, output_path in zip(centroid_indices, [os.path.join(output_folder, f'unique_image_{i}.jpg') for i in range(len(centroid_indices))]):\n",
    "    img = trainImg[img_index]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    imsave(output_path, img)\n",
    "    plt.close()\n",
    "\n",
    "print(\"Eindeutige Bilder (Centroids) wurden im Zielordner gespeichert:\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste für Trainingsbilder\n",
    "trainImg = []\n",
    "\n",
    "# Pfad zum Ordner mit den Bildern\n",
    "folder_path = './PraktikumCV/ASL_Alphabet_Dataset/asl_alphabet_train/E/'\n",
    "\n",
    "# Durchsuche alle Unterordner nach .jpg und .jpeg Dateien und füge sie zur Liste hinzu\n",
    "for img_path in glob.glob(folder_path + '/*.jp*g', recursive=True):\n",
    "    trainImg.append(resize(imread(img_path), (200, 200)))\n",
    "\n",
    "# Konvertieren Sie Bilder in eine 2D-Array-Darstellung\n",
    "image_array = np.array([img.flatten() for img in trainImg])\n",
    "\n",
    "# Drucke die Anzahl der gefundenen Bilder\n",
    "print(f\"Anzahl der gefundenen Bilder: {len(trainImg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden Sie das VGG16-Modell vor, ohne die oberste Schicht (ohne Klassifizierungsschicht)\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "# Funktion zur Feature-Extraktion mit VGG16\n",
    "def extract_features(img_array):\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = vgg16_model.predict(img_array)\n",
    "    return features.reshape((len(img_array), -1))\n",
    "\n",
    "# Feature-Extraktion mit VGG16\n",
    "vgg16_features = extract_features(np.array(trainImg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imsave\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Annahme: vgg16_features und trainImg sind bereits definiert\n",
    "\n",
    "# Features normalisieren\n",
    "normalized_features = StandardScaler().fit_transform(vgg16_features)\n",
    "\n",
    "# Hier KDTree\n",
    "kdtree = KDTree(normalized_features, metric='euclidean')\n",
    "\n",
    "# Festlege der Entfernungsschwelle für Clustering\n",
    "distance_threshold = 2\n",
    "\n",
    "# Finde Nachbarn für jeden Punkt\n",
    "neighbors = kdtree.query_radius(normalized_features, distance_threshold)\n",
    "\n",
    "# Erstelle Cluster-Labels\n",
    "labels = np.zeros(len(normalized_features), dtype=int)\n",
    "current_label = 1\n",
    "\n",
    "for i, neighbor_list in enumerate(neighbors):\n",
    "    if labels[i] == 0:  # Punkt noch nicht in einem Cluster\n",
    "        labels[neighbor_list] = current_label\n",
    "        current_label += 1\n",
    "\n",
    "# Berechne die Centroids der Cluster\n",
    "cluster_centroids = []\n",
    "for cluster_label in np.unique(labels):\n",
    "        cluster_points = normalized_features[labels == cluster_label]\n",
    "        cluster_centroid = np.mean(cluster_points, axis=0)\n",
    "        cluster_centroids.append(cluster_centroid)\n",
    "\n",
    "cluster_centroids = np.array(cluster_centroids)\n",
    "\n",
    "# Extrahiere eindeutige Bilder basierend auf den Clustern\n",
    "unique_images = [trainImg[i] for i in np.unique(labels) if i != -1]\n",
    "\n",
    "# Finde die Indizes der Centroids in den ursprünglichen Bildern\n",
    "centroid_indices = []\n",
    "for centroid in cluster_centroids:\n",
    "    nearest_neighbor_distance, nearest_neighbor_index = kdtree.query(centroid.reshape(1, -1), k=1)\n",
    "    centroid_indices.append(nearest_neighbor_index[0][0])\n",
    "\n",
    "# Extrahiere die Bilder der Centroids\n",
    "centroid_images = [trainImg[i] for i in centroid_indices]\n",
    "\n",
    "# Speicherpfad für eindeutige Bilder\n",
    "output_folder = './PraktikumCV/ASL_unique/E/'\n",
    "os.makedirs(output_folder, exist_ok=True)  # Erstelle den Ordner, falls er nicht existiert\n",
    "\n",
    "# Batch-Verarbeitung und direktes Speichern\n",
    "for img_index, output_path in zip(centroid_indices, [os.path.join(output_folder, f'unique_image_{i}.jpg') for i in range(len(centroid_indices))]):\n",
    "    img = trainImg[img_index]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    imsave(output_path, img)\n",
    "    plt.close()\n",
    "\n",
    "print(\"Eindeutige Bilder (Centroids) wurden im Zielordner gespeichert:\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste für Trainingsbilder\n",
    "trainImg = []\n",
    "\n",
    "# Pfad zum Ordner mit den Bildern\n",
    "folder_path = './PraktikumCV/ASL_Alphabet_Dataset/asl_alphabet_train/F/'\n",
    "\n",
    "# Durchsuche alle Unterordner nach .jpg und .jpeg Dateien und füge sie zur Liste hinzu\n",
    "for img_path in glob.glob(folder_path + '/*.jp*g', recursive=True):\n",
    "    trainImg.append(resize(imread(img_path), (200, 200)))\n",
    "\n",
    "# Konvertieren Sie Bilder in eine 2D-Array-Darstellung\n",
    "image_array = np.array([img.flatten() for img in trainImg])\n",
    "\n",
    "# Drucke die Anzahl der gefundenen Bilder\n",
    "print(f\"Anzahl der gefundenen Bilder: {len(trainImg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden Sie das VGG16-Modell vor, ohne die oberste Schicht (ohne Klassifizierungsschicht)\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "# Funktion zur Feature-Extraktion mit VGG16\n",
    "def extract_features(img_array):\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = vgg16_model.predict(img_array)\n",
    "    return features.reshape((len(img_array), -1))\n",
    "\n",
    "# Feature-Extraktion mit VGG16\n",
    "vgg16_features = extract_features(np.array(trainImg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imsave\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Annahme: vgg16_features und trainImg sind bereits definiert\n",
    "\n",
    "# Features normalisieren\n",
    "normalized_features = StandardScaler().fit_transform(vgg16_features)\n",
    "\n",
    "# Hier KDTree\n",
    "kdtree = KDTree(normalized_features, metric='euclidean')\n",
    "\n",
    "# Festlege der Entfernungsschwelle für Clustering\n",
    "distance_threshold = 2\n",
    "\n",
    "# Finde Nachbarn für jeden Punkt\n",
    "neighbors = kdtree.query_radius(normalized_features, distance_threshold)\n",
    "\n",
    "# Erstelle Cluster-Labels\n",
    "labels = np.zeros(len(normalized_features), dtype=int)\n",
    "current_label = 1\n",
    "\n",
    "for i, neighbor_list in enumerate(neighbors):\n",
    "    if labels[i] == 0:  # Punkt noch nicht in einem Cluster\n",
    "        labels[neighbor_list] = current_label\n",
    "        current_label += 1\n",
    "\n",
    "# Berechne die Centroids der Cluster\n",
    "cluster_centroids = []\n",
    "for cluster_label in np.unique(labels):\n",
    "        cluster_points = normalized_features[labels == cluster_label]\n",
    "        cluster_centroid = np.mean(cluster_points, axis=0)\n",
    "        cluster_centroids.append(cluster_centroid)\n",
    "\n",
    "cluster_centroids = np.array(cluster_centroids)\n",
    "\n",
    "# Extrahiere eindeutige Bilder basierend auf den Clustern\n",
    "unique_images = [trainImg[i] for i in np.unique(labels) if i != -1]\n",
    "\n",
    "# Finde die Indizes der Centroids in den ursprünglichen Bildern\n",
    "centroid_indices = []\n",
    "for centroid in cluster_centroids:\n",
    "    nearest_neighbor_distance, nearest_neighbor_index = kdtree.query(centroid.reshape(1, -1), k=1)\n",
    "    centroid_indices.append(nearest_neighbor_index[0][0])\n",
    "\n",
    "# Extrahiere die Bilder der Centroids\n",
    "centroid_images = [trainImg[i] for i in centroid_indices]\n",
    "\n",
    "# Speicherpfad für eindeutige Bilder\n",
    "output_folder = './PraktikumCV/ASL_unique/F/'\n",
    "os.makedirs(output_folder, exist_ok=True)  # Erstelle den Ordner, falls er nicht existiert\n",
    "\n",
    "# Batch-Verarbeitung und direktes Speichern\n",
    "for img_index, output_path in zip(centroid_indices, [os.path.join(output_folder, f'unique_image_{i}.jpg') for i in range(len(centroid_indices))]):\n",
    "    img = trainImg[img_index]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    imsave(output_path, img)\n",
    "    plt.close()\n",
    "\n",
    "print(\"Eindeutige Bilder (Centroids) wurden im Zielordner gespeichert:\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste für Trainingsbilder\n",
    "trainImg = []\n",
    "\n",
    "# Pfad zum Ordner mit den Bildern\n",
    "folder_path = './PraktikumCV/ASL_Alphabet_Dataset/asl_alphabet_train/G/'\n",
    "\n",
    "# Durchsuche alle Unterordner nach .jpg und .jpeg Dateien und füge sie zur Liste hinzu\n",
    "for img_path in glob.glob(folder_path + '/*.jp*g', recursive=True):\n",
    "    trainImg.append(resize(imread(img_path), (200, 200)))\n",
    "\n",
    "# Konvertieren Sie Bilder in eine 2D-Array-Darstellung\n",
    "image_array = np.array([img.flatten() for img in trainImg])\n",
    "\n",
    "# Drucke die Anzahl der gefundenen Bilder\n",
    "print(f\"Anzahl der gefundenen Bilder: {len(trainImg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden Sie das VGG16-Modell vor, ohne die oberste Schicht (ohne Klassifizierungsschicht)\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "# Funktion zur Feature-Extraktion mit VGG16\n",
    "def extract_features(img_array):\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = vgg16_model.predict(img_array)\n",
    "    return features.reshape((len(img_array), -1))\n",
    "\n",
    "# Feature-Extraktion mit VGG16\n",
    "vgg16_features = extract_features(np.array(trainImg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imsave\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Annahme: vgg16_features und trainImg sind bereits definiert\n",
    "\n",
    "# Features normalisieren\n",
    "normalized_features = StandardScaler().fit_transform(vgg16_features)\n",
    "\n",
    "# Hier KDTree\n",
    "kdtree = KDTree(normalized_features, metric='euclidean')\n",
    "\n",
    "# Festlege der Entfernungsschwelle für Clustering\n",
    "distance_threshold = 2\n",
    "\n",
    "# Finde Nachbarn für jeden Punkt\n",
    "neighbors = kdtree.query_radius(normalized_features, distance_threshold)\n",
    "\n",
    "# Erstelle Cluster-Labels\n",
    "labels = np.zeros(len(normalized_features), dtype=int)\n",
    "current_label = 1\n",
    "\n",
    "for i, neighbor_list in enumerate(neighbors):\n",
    "    if labels[i] == 0:  # Punkt noch nicht in einem Cluster\n",
    "        labels[neighbor_list] = current_label\n",
    "        current_label += 1\n",
    "\n",
    "# Berechne die Centroids der Cluster\n",
    "cluster_centroids = []\n",
    "for cluster_label in np.unique(labels):\n",
    "        cluster_points = normalized_features[labels == cluster_label]\n",
    "        cluster_centroid = np.mean(cluster_points, axis=0)\n",
    "        cluster_centroids.append(cluster_centroid)\n",
    "\n",
    "cluster_centroids = np.array(cluster_centroids)\n",
    "\n",
    "# Extrahiere eindeutige Bilder basierend auf den Clustern\n",
    "unique_images = [trainImg[i] for i in np.unique(labels) if i != -1]\n",
    "\n",
    "# Finde die Indizes der Centroids in den ursprünglichen Bildern\n",
    "centroid_indices = []\n",
    "for centroid in cluster_centroids:\n",
    "    nearest_neighbor_distance, nearest_neighbor_index = kdtree.query(centroid.reshape(1, -1), k=1)\n",
    "    centroid_indices.append(nearest_neighbor_index[0][0])\n",
    "\n",
    "# Extrahiere die Bilder der Centroids\n",
    "centroid_images = [trainImg[i] for i in centroid_indices]\n",
    "\n",
    "# Speicherpfad für eindeutige Bilder\n",
    "output_folder = './PraktikumCV/ASL_unique/G/'\n",
    "os.makedirs(output_folder, exist_ok=True)  # Erstelle den Ordner, falls er nicht existiert\n",
    "\n",
    "# Batch-Verarbeitung und direktes Speichern\n",
    "for img_index, output_path in zip(centroid_indices, [os.path.join(output_folder, f'unique_image_{i}.jpg') for i in range(len(centroid_indices))]):\n",
    "    img = trainImg[img_index]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    imsave(output_path, img)\n",
    "    plt.close()\n",
    "\n",
    "print(\"Eindeutige Bilder (Centroids) wurden im Zielordner gespeichert:\", output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
